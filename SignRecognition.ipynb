{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8c77aa",
   "metadata": {},
   "source": [
    "### Import dependecies and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437725ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90456b50",
   "metadata": {},
   "source": [
    "### Webcam test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc1c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables from Mediapipe for detection and drawing\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe6b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection(img, model): This function process an image and make predictions about what detects (hands, face, pose)\n",
    "#     img:The image we want to process\n",
    "#     model: The model that will make the predictions\n",
    "\n",
    "def detection(img, model):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Color conversion to RGB\n",
    "    img.flags.writeable = False\n",
    "    results = model.process(img) # Image processing\n",
    "    img.flags.writeable = True\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Back to original color (BGR)\n",
    "    return img, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d4c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_landmarks(img, results): This function show the conections and landmarks of face, hands and pose. Also add styles.\n",
    "#     img: The image we want to process\n",
    "#     results: Results given by the predictor\n",
    "\n",
    "def show_landmarks(img, results):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        img, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "        mp_drawing.DrawingSpec(color=(0,0,255), thickness=1, circle_radius=1),\n",
    "        mp_drawing.DrawingSpec(color=(10,255,0), thickness=1, circle_radius=1)\n",
    "    )\n",
    "    mp_drawing.draw_landmarks(\n",
    "        img, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "         mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=1),\n",
    "         mp_drawing.DrawingSpec(color=(234,232,24), thickness=2, circle_radius=2)\n",
    "    )\n",
    "    mp_drawing.draw_landmarks(\n",
    "        img, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "         mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=1),\n",
    "         mp_drawing.DrawingSpec(color=(228,19,206), thickness=2, circle_radius=2)\n",
    "    )\n",
    "    mp_drawing.draw_landmarks(\n",
    "        img, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "         mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=1),\n",
    "         mp_drawing.DrawingSpec(color=(228,19,206), thickness=2, circle_radius=2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd6d902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# capture = cv2.VideoCapture(0)\n",
    "\n",
    "# if capture.isOpened() is False: print(\"Camera is not available\")\n",
    "    \n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: # Setting mediapipe model\n",
    "#     while capture.isOpened():\n",
    "        \n",
    "#         # Read frames and show them\n",
    "#         _, frame = capture.read()\n",
    "        \n",
    "#         # Model results prediction\n",
    "#         img, results = detection(frame, holistic)\n",
    "        \n",
    "#         # Show landmarks\n",
    "#         show_landmarks(img, results)\n",
    "        \n",
    "#         cv2.imshow(\"OpenCV video\", img)\n",
    "\n",
    "#         if cv2.waitKey(1) == ord(\"q\"):\n",
    "#             break\n",
    "#     capture.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d748287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REVISAR'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''REVISAR'''\n",
    "# # The face and hand model will return nothing if face or hands are not being detected\n",
    "# print(\"Num face landmarks =\", len(results.face_landmarks.landmark))\n",
    "# len(results.right_hand_landmarks.landmark)\n",
    "# print(\"Right hand landmarks type =\", type(results.right_hand_landmarks))\n",
    "# print(\"Left hand landmarks type =\", type(results.left_hand_landmarks))\n",
    "\n",
    "# # The pose model will return landmarks but their visibility value will be very low\n",
    "# print(\"Num pose landmarks =\", len(results.pose_landmarks.landmark))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40da790",
   "metadata": {},
   "source": [
    "### Get landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f27175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO: Optimizar'''\n",
    "\n",
    "NUM_POSE_LANDMARKS = 33 * 4 # 33 landmarks. 3 coordinates and 1 visibility attribute per landmark\n",
    "NUM_FACE_LANDMARKS = 468 * 3 # 468 landmarks. 3 coordinates per landmark\n",
    "NUM_HAND_LANDMARKS = 21 * 3 # 21 landmarks. 3 coordinates per landmark\n",
    "\n",
    "def get_landmarks(results):\n",
    "    \n",
    "    # Face\n",
    "    face = []\n",
    "    if results.face_landmarks:\n",
    "        for result in results.face_landmarks.landmark:\n",
    "            landmark = [result.x, result.y, result.z]\n",
    "            face.append(landmark)\n",
    "        face = np.array(face).flatten()\n",
    "    else:\n",
    "        face = np.zeros(NUM_FACE_LANDMARS)\n",
    "    face = np.array(face).flatten()\n",
    "    \n",
    "    # Pose\n",
    "    pose = []\n",
    "    if results.pose_landmarks:\n",
    "        for result in results.pose_landmarks.landmark:\n",
    "            landmark = [result.x, result.y, result.z, result.visibility]\n",
    "            pose.append(landmark)\n",
    "        pose = np.array(pose).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(NUM_POSE_LANDMARS)\n",
    "    pose = np.array(pose).flatten()\n",
    "    \n",
    "    #Left hand\n",
    "    left_hand = []\n",
    "    if results.left_hand_landmarks:\n",
    "        for result in results.left_hand_landmarks.landmark:\n",
    "            landmark = [result.x, result.y, result.z]\n",
    "            left_hand.append(landmark)\n",
    "    else:\n",
    "        left_hand = np.zeros(NUM_HAND_LANDMARKS)\n",
    "    left_hand = np.array(left_hand).flatten()\n",
    "    \n",
    "    # Right hand\n",
    "    right_hand = []\n",
    "    if results.right_hand_landmarks.landmark:\n",
    "        for result in results.right_hand_landmarks.landmark:\n",
    "            landmark = [result.x, result.y, result.z]\n",
    "            right_hand.append(landmark)\n",
    "    else:\n",
    "        right_hand = np.zeros(NUM_HAND_LANDMARKS)\n",
    "    right_hand = np.array(right_hand).flatten()\n",
    "    \n",
    "    # Return all landmarks concatenated\n",
    "    return np.concatenate([face, pose, left_hand, right_hand])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700f67a",
   "metadata": {},
   "source": [
    "### Setting up folders for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4a85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"dataset_ini\")\n",
    "signs = np.array([\"hola\", \"adios\", \"gracias\"])\n",
    "num_videos = 30\n",
    "len_videos = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47bc7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sign in signs:\n",
    "    for video_index in range(num_videos):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, sign, str(video_index)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849338c",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6027fe23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_landmarks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\FRANS~1.DES\\AppData\\Local\\Temp/ipykernel_9028/3852105896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;31m# Show landmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mshow_landmarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[1;31m# Capture funtionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'show_landmarks' is not defined"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "if capture.isOpened() is False: print(\"La camara no esta disponible\")\n",
    "    \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: # Setting mediapipe model\n",
    "    for sign in signs:\n",
    "        for video in range(num_videos):\n",
    "            for video_frame in range(len_videos):\n",
    "                \n",
    "                # Read frames and show them\n",
    "                _, frame = capture.read()\n",
    "\n",
    "                # Model results prediction\n",
    "                img, results = detection(frame, holistic)    \n",
    "\n",
    "                # Show landmarks\n",
    "                show_landmarks(img, results)\n",
    "                \n",
    "                # Capture funtionality\n",
    "                if video_frame==0:\n",
    "                    cv2.putText(img, 'Comenzando captura', (150,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,230,0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(img, 'Capturando frames para {}. Video {}'.format(sign, video), (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,230,0), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow(\"OpenCV video\", img)\n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.putText(img, 'Capturando frames para {}. Video {}'.format(sign, video), (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,230,0), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow(\"OpenCV video\", img)\n",
    "                    \n",
    "                # Landmarks saving\n",
    "                all_landmarks = getLandmarks(results)\n",
    "                path = os.path.join(DATA_PATH, sign, str(video))\n",
    "                np.save(path, all_landmarks)\n",
    "                \n",
    "                if cv2.waitKey(1) == ord(\"q\"):\n",
    "                    break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2afec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
